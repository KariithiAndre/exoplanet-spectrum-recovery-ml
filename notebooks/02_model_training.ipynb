{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c0b097",
   "metadata": {},
   "source": [
    "# Model Training Guide\n",
    "\n",
    "This notebook covers training the spectrum denoiser and retrieval models.\n",
    "\n",
    "## Contents\n",
    "1. Generating synthetic training data\n",
    "2. Training the denoiser model\n",
    "3. Evaluating model performance\n",
    "4. Fine-tuning on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5711a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from models.architectures.denoiser import create_denoiser\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f3999",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Training Data\n",
    "\n",
    "We create synthetic transmission spectra using simplified atmospheric models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_spectrum(wavelength, n_features=5, base_depth=100):\n",
    "    \"\"\"Generate a synthetic transmission spectrum with random molecular features.\"\"\"\n",
    "    spectrum = np.ones_like(wavelength) * base_depth\n",
    "    \n",
    "    for _ in range(n_features):\n",
    "        # Random feature parameters\n",
    "        center = np.random.uniform(wavelength.min() + 0.5, wavelength.max() - 0.5)\n",
    "        width = np.random.uniform(0.05, 0.3)\n",
    "        depth = np.random.uniform(5, 30)\n",
    "        \n",
    "        # Add Gaussian absorption feature\n",
    "        spectrum += depth * np.exp(-((wavelength - center) ** 2) / (2 * width ** 2))\n",
    "    \n",
    "    return spectrum\n",
    "\n",
    "def add_noise(spectrum, snr):\n",
    "    \"\"\"Add Gaussian noise based on signal-to-noise ratio.\"\"\"\n",
    "    noise_std = spectrum.std() / snr\n",
    "    noise = np.random.normal(0, noise_std, len(spectrum))\n",
    "    return spectrum + noise\n",
    "\n",
    "# Generate dataset\n",
    "n_samples = 1000\n",
    "n_wavelengths = 512\n",
    "wavelength = np.linspace(0.5, 5.0, n_wavelengths)\n",
    "\n",
    "clean_spectra = np.zeros((n_samples, n_wavelengths))\n",
    "noisy_spectra = np.zeros((n_samples, n_wavelengths))\n",
    "\n",
    "for i in tqdm(range(n_samples), desc='Generating spectra'):\n",
    "    n_features = np.random.randint(3, 8)\n",
    "    clean_spectra[i] = generate_synthetic_spectrum(wavelength, n_features)\n",
    "    snr = np.random.uniform(10, 50)\n",
    "    noisy_spectra[i] = add_noise(clean_spectra[i], snr)\n",
    "\n",
    "print(f\"Generated {n_samples} spectra with {n_wavelengths} wavelength points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed54038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few examples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.plot(wavelength, noisy_spectra[i], 'b.', alpha=0.5, markersize=2, label='Noisy')\n",
    "    ax.plot(wavelength, clean_spectra[i], 'r-', linewidth=1.5, label='Clean')\n",
    "    ax.set_xlabel('Wavelength (μm)')\n",
    "    ax.set_ylabel('Transit Depth (ppm)')\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f579e0d",
   "metadata": {},
   "source": [
    "## 2. Prepare DataLoaders and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X = torch.FloatTensor(noisy_spectra).unsqueeze(1)  # (N, 1, L)\n",
    "y = torch.FloatTensor(clean_spectra).unsqueeze(1)\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_denoiser(model_type='v1', base_channels=32, num_residual_blocks=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ae7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    train_loss = epoch_train_loss / len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            epoch_val_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    val_loss = epoch_val_loss / len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../models/checkpoints/denoiser_demo.pt')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855387d7",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('../models/checkpoints/denoiser_demo.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Test on validation set\n",
    "with torch.no_grad():\n",
    "    X_val_gpu = X_val.to(device)\n",
    "    predictions = model(X_val_gpu).cpu().numpy()\n",
    "\n",
    "# Calculate SNR improvement\n",
    "input_error = np.mean((noisy_spectra[train_size:] - clean_spectra[train_size:]) ** 2, axis=1)\n",
    "output_error = np.mean((predictions.squeeze() - clean_spectra[train_size:]) ** 2, axis=1)\n",
    "snr_improvement = 10 * np.log10(input_error / output_error)\n",
    "\n",
    "print(f\"Average SNR improvement: {snr_improvement.mean():.2f} ± {snr_improvement.std():.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814be047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = i\n",
    "    ax.plot(wavelength, X_val[idx, 0].numpy(), 'b.', alpha=0.3, markersize=2, label='Noisy')\n",
    "    ax.plot(wavelength, predictions[idx, 0], 'g-', linewidth=1.5, label='Recovered')\n",
    "    ax.plot(wavelength, y_val[idx, 0].numpy(), 'r--', linewidth=1, label='Ground Truth')\n",
    "    ax.set_xlabel('Wavelength (μm)')\n",
    "    ax.set_ylabel('Transit Depth (ppm)')\n",
    "    ax.set_title(f'SNR Improvement: {snr_improvement[idx]:.1f} dB')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
